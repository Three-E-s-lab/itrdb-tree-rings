{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7hG3yzhhiPv"
      },
      "source": [
        "# Modified/Optimized copy of Sept 25th version of the script:\n",
        "https://colab.research.google.com/drive/13zYtgUggPKa0aPVWNTLgckn3F8sz5dd1#scrollTo=608iiBHu8gbb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IihmkilimgQ"
      },
      "source": [
        "## Report of Main changes summary from Sept 25 - Oct 4:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCsziV5hjTj9"
      },
      "source": [
        "Here’s a summary of the key changes from the original script you provided on Sep 25 to the current working script:\n",
        "\n",
        "### 1. Refactor of `aggregate_monthly_degree_days` Function\n",
        "**Original Version:**\n",
        "- The aggregate_monthly_degree_days function worked with individual (year, month) arguments and handled region boundaries.\n",
        "\n",
        "**Updated Version:**\n",
        "- The updated script now works by unpacking a (year, month) tuple inside aggregate_monthly_degree_days, and region handling has been removed.\n",
        "\n",
        "**Benefit**:\n",
        "- allows for a more streamlined approach when processing a list of (year, month) pairs,\n",
        "- simplifying the code by focusing only on the data processing itself rather than additional region constraints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOF1qlJolifx"
      },
      "source": [
        "\n",
        "### 2. Handling 4-Hourly Degree Days Calculation\n",
        "**Original Version:**\n",
        "- The 4-hourly aggregation logic was not explicitly managed.\n",
        "\n",
        "**Updated Version:**\n",
        "- The compute_4hourly_degree_days function was streamlined to process 4-hourly intervals, and the date properties (like hour and day_of_year) are added directly using the add_date_properties function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn6IYhCVllig"
      },
      "source": [
        "\n",
        "\n",
        "### 3. Use of Python Tuples for (year, month) and ee.List in generate_monthly_aggregates\n",
        "**Original Version:**\n",
        "- The original approach involved passing year and month as individual parameters to various functions.\n",
        "\n",
        "**Updated Version**:\n",
        "- The script now passes monthly dates as a list of tuples (i.e., [(2023, 1), (2023, 2)]) to the generate_monthly_aggregates function, and converts them into Earth Engine’s ee.List to work within GEE’s ecosystem.\n",
        "\n",
        "**Benefit:**\n",
        "- This allows the code to process all monthly data in a more concise and efficient way using Earth Engine’s .map() function, which results in more efficient and scalable processing for multiple months and years.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUk4iuoplrT5"
      },
      "source": [
        "\n",
        "### 4. Efficient Mapping and Image Collection Creation\n",
        "**Original Version:**\n",
        "- The script processed individual months and years in loops and used filters for regional boundaries.\n",
        "\n",
        "**Updated Version:**\n",
        "- The new generate_monthly_aggregates function processes a list of dates using Earth Engine’s .map() functionality, which reduces the overhead of nested loops and simplifies the handling of multiple months and years.\n",
        "\n",
        "**Benefit**: It allows the processing to be handled more efficiently within Earth Engine’s framework and is more scalable for large datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4Arxujklu7K"
      },
      "source": [
        "\n",
        "### 5. Zonal Statistics Handling Remained Unchanged (SAME)\n",
        "- The zonal_stats function was carried over from the original script without modification, as the original zonal statistics implementation was robust and compatible with the new data structures.\n",
        "- The key functionality (applying reducers to feature collections) remained intact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB5dGKWOlx0T"
      },
      "source": [
        "\n",
        "### 6. Optimized Export Process\n",
        "**Original Version** : The export process was somewhat repetitive, with individual year-month combinations being handled manually.\n",
        "\n",
        "**Updated Version**: The export process now iterates through all monthly_dates generated by the updated generate_monthly_aggregates function, ensuring that the correct data is passed to the zonal statistics function and exported efficiently.\n",
        "\n",
        "**Benefit**: This change allows for faster and more flexible export processes, handling multiple months and years in one sweep, reducing manual setup for each export job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLaHtj49lzW4"
      },
      "source": [
        "\n",
        "### 7. Added Flexibility in Base Temperatures\n",
        "**Original Version**: The base temperature handling was more rigid.\n",
        "\n",
        "**Updated Version**: The generate_monthly_aggregates function now allows for multiple base temperatures, processing each temperature threshold through a list, and combining the results in a single image collection.\n",
        "\n",
        " **Benefit** : This allows the user to compute degree days across a range of temperature thresholds in one run.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWqii35zl0vu"
      },
      "source": [
        "\n",
        "### Summary of the Key Changes:\n",
        "- (year, month) Tuple Handling: Refactor to pass monthly dates as tuples and process them in a more efficient way.\n",
        "- 4-Hourly Degree Day Calculation: Proper handling of 4-hour intervals, including adding date properties and computing daily averages to account for missing data.\n",
        "- Efficient .map() Usage: Replacing loops with Earth Engine’s .map() to handle all monthly dates efficiently.\n",
        "- Streamlined Export Process: Simplified the export logic to iterate over months and years using zonal statistics.\n",
        "- Flexible Base Temperature Handling: Added the ability to compute degree days across a range of temperatures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpHmqUXIl2LC"
      },
      "source": [
        "#START"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rvtwpIGQPALt"
      },
      "outputs": [],
      "source": [
        "PROJECT = \"treegrowth-471820\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9IwJuJHjA7U"
      },
      "source": [
        "# Authorization and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qjLcDTocPB1G"
      },
      "outputs": [],
      "source": [
        "#!gcloud auth login --project {PROJECT}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zP9gXF6nVJzU"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import ee\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoS62UurVdxb",
        "outputId": "e3f53abe-8f73-4bf1-a118-c33ec48a1722"
      },
      "outputs": [],
      "source": [
        "ee.Authenticate()\n",
        "ee.Initialize(project=PROJECT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXmn3WfDTvFZ"
      },
      "source": [
        "Function to filter 4-hourly intervals and add day properties to each image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc-awnBGUPhE"
      },
      "source": [
        "# Computing Degree-Day Values from 4-Hourly Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pCZELcsVzua"
      },
      "source": [
        "1. Helps track and group temperature data into 4-hour intervals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "608iiBHu8gbb"
      },
      "outputs": [],
      "source": [
        "def add_date_properties(image):\n",
        "    date = ee.Date(image.get('system:time_start'))\n",
        "    hour = date.get('hour')\n",
        "    day_of_year = date.getRelative('day', 'year')\n",
        "    return image.set('day_of_year', day_of_year).set('hour', hour)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj4ayZfMV1cY"
      },
      "source": [
        "2. Calculates degree days relative to the base temperature (e.g., -20°C)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NeUibmvWUOzL"
      },
      "outputs": [],
      "source": [
        "def compute_4hourly_degree_days(image, base_temp=-20):\n",
        "    temp_band = image.select('temperature_2m').subtract(273.15)  # Convert Kelvin to Celsius\n",
        "    degree_days = temp_band.subtract(base_temp).max(0)\n",
        "    return degree_days.rename(f'degree_days_above_{base_temp}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkI3UYRpWd68"
      },
      "source": [
        "3. For each year and month, the function filters ERA5 hourly\n",
        "temperature data.\n",
        "\n",
        "- It applies the 4-hourly degree days calculation.\n",
        "\n",
        "- Degree days are aggregated by day and converted into monthly sums."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cihxQl2wUUJ-"
      },
      "outputs": [],
      "source": [
        "def aggregate_monthly_degree_days(monthly_date, base_temp):\n",
        "    year, month = monthly_date  # unpacking a tuple\n",
        "    start_date = ee.Date.fromYMD(year, month, 1)\n",
        "    end_date = start_date.advance(1, 'month')\n",
        "\n",
        "    era_hourly = ee.ImageCollection(\"ECMWF/ERA5_LAND/HOURLY\").filterDate(start_date, end_date)\n",
        "\n",
        "    # compute 4-hourly degree days + add date properties\n",
        "    degree_days = era_hourly.map(lambda img: compute_4hourly_degree_days(img, base_temp)).map(add_date_properties)\n",
        "\n",
        "    # sum degree days by day\n",
        "    daily_sum = degree_days.reduce(ee.Reducer.sum())\n",
        "    # count the number of 4-hour intervals per day\n",
        "    daily_count = degree_days.reduce(ee.Reducer.count())\n",
        "    # calculate the average degree days per day to account for missing data\n",
        "    daily_avg = daily_sum.divide(daily_count).rename(f'daily_avg_degree_days_above_{base_temp}')\n",
        "\n",
        "    # sum the daily averages over the month\n",
        "    monthly_sum = daily_avg.reduce(ee.Reducer.sum()).rename(f'monthly_sum_degree_days_above_{base_temp}')\n",
        "\n",
        "    # add year and month as bands\n",
        "    year_band = ee.Image.constant(year).rename('year').toFloat()\n",
        "    month_band = ee.Image.constant(month).rename('month').toFloat()\n",
        "\n",
        "    # Combine results\n",
        "    combined = monthly_sum.addBands(year_band).addBands(month_band)\n",
        "\n",
        "    return combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3Fj4puSWkei"
      },
      "source": [
        "4. Aggregates temperature data (max, min, mean, sum) for each month.\n",
        "Adjusts for Celsius conversion if the temperature is the band."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UvFhMDIyUV00"
      },
      "outputs": [],
      "source": [
        "def aggregate_monthly_data(year, month, band_name, operation):\n",
        "    start_date = ee.Date.fromYMD(year, month, 1)\n",
        "    end_date = start_date.advance(1, 'month')\n",
        "    era_hourly = ee.ImageCollection(\"ECMWF/ERA5_LAND/HOURLY\").filterDate(start_date, end_date).select(band_name)\n",
        "\n",
        "    if operation == 'max':\n",
        "        aggregated_data = era_hourly.max()\n",
        "    elif operation == 'min':\n",
        "        aggregated_data = era_hourly.min()\n",
        "    elif operation == 'mean':\n",
        "        aggregated_data = era_hourly.mean()\n",
        "    elif operation == 'sum':\n",
        "        aggregated_data = era_hourly.sum()\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported operation: {operation}\")\n",
        "\n",
        "    # Convert temperature from Kelvin to Celsius if the band name includes 'temperature'\n",
        "    if 'temperature' in band_name:\n",
        "        aggregated_data = aggregated_data.subtract(273.15)\n",
        "\n",
        "    return aggregated_data.set('system:time_start', start_date.millis())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJYyNJP_Wrp5"
      },
      "source": [
        "5. This function loops through all the months of the specified years.\n",
        "\n",
        "It computes maximum, minimum, and mean temperature values as well as precipitation.\n",
        "Degree day values for multiple base temperatures are calculated and concatenated into a single image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aA8Jerx0U8vN"
      },
      "outputs": [],
      "source": [
        "def generate_monthly_aggregates(monthly_dates, base_temps):\n",
        "    def process_monthly_date(monthly_date):\n",
        "        year = ee.Number(monthly_date.get(0))\n",
        "        month = ee.Number(monthly_date.get(1))\n",
        "\n",
        "        monthly_max = aggregate_monthly_data(year, month, 'temperature_2m', 'max').rename('max_temp')\n",
        "        monthly_min = aggregate_monthly_data(year, month, 'temperature_2m', 'min').rename('min_temp')\n",
        "        monthly_mean = aggregate_monthly_data(year, month, 'temperature_2m', 'mean').rename('mean_temp')\n",
        "        monthly_precip = aggregate_monthly_data(year, month, 'total_precipitation', 'sum').rename('total_precip')\n",
        "\n",
        "        degree_days_list = [aggregate_monthly_degree_days((year, month), base_temp).select(f'monthly_sum_degree_days_above_{base_temp}')\n",
        "                            for base_temp in base_temps]\n",
        "        degree_days_combined = ee.Image.cat(degree_days_list)\n",
        "\n",
        "        # Add year and month as bands\n",
        "        year_band = ee.Image.constant(year).rename('year').toFloat()\n",
        "        month_band = ee.Image.constant(month).rename('month').toFloat()\n",
        "\n",
        "        # Combine everything\n",
        "        combined = monthly_max.addBands(monthly_min).addBands(monthly_mean).addBands(monthly_precip).addBands(degree_days_combined).addBands(year_band).addBands(month_band)\n",
        "        return combined\n",
        "\n",
        "    # Convert monthly dates to an ee.List -> Python list of tuples into an ee.List of ee.Lists\n",
        "    ee_monthly_dates = ee.List([ee.List([ee.Number(year), ee.Number(month)]) for year, month in monthly_dates])\n",
        "\n",
        "    # Apply the process for each monthly date using .map()\n",
        "    monthly_aggregates = ee.ImageCollection.fromImages(\n",
        "        ee_monthly_dates.map(lambda monthly_date: process_monthly_date(ee.List(monthly_date)))\n",
        "    )\n",
        "\n",
        "    return monthly_aggregates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "O1wcGNoIGTVK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 598 sites\n"
          ]
        }
      ],
      "source": [
        "#coordinates = ee.FeatureCollection(\"projects/era5-land-project/assets/itrdb_locations_unique_with_duplicate_lat_lon_info\")\n",
        "# Load Canada sites\n",
        "import pandas as pd \n",
        "CSV_PATH      = \"ring_width_output_new/tree_ring_coordinates.csv\"\n",
        "sites_df = pd.read_csv(CSV_PATH)\n",
        "sites_df = sites_df.dropna(subset=[\"lat\",\"lon\"]).copy()\n",
        "sites_df[\"site_id\"] = sites_df.get(\"site_id\", pd.Series([f\"site_{i:06d}\" for i in range(len(sites_df))]))\n",
        "print(f\"Loaded {len(sites_df)} sites\")\n",
        "\n",
        "def _row_to_feat(r):\n",
        "    geom = ee.Geometry.Point([float(r[\"lon\"]), float(r[\"lat\"])])\n",
        "    return ee.Feature(geom, {\"site_id\": str(r[\"site_id\"])})\n",
        "coordinates = ee.FeatureCollection([_row_to_feat(r) for _, r in sites_df.iterrows()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yiZc_V8Xt5C"
      },
      "source": [
        "## Testing for a smaller range of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNM4IX8uXxCT",
        "outputId": "15b9c401-5390-4074-d56f-17f111f86b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "['max_temp', 'min_temp', 'mean_temp', 'total_precip', 'monthly_sum_degree_days_above_-5', 'monthly_sum_degree_days_above_-4', 'monthly_sum_degree_days_above_-3', 'monthly_sum_degree_days_above_-2', 'monthly_sum_degree_days_above_-1', 'year', 'month']\n"
          ]
        }
      ],
      "source": [
        "monthly_aggregates_ic = generate_monthly_aggregates([(2023, 1), (2023, 2)], list(range(-5, 0)))\n",
        "\n",
        "print(monthly_aggregates_ic.size().getInfo())\n",
        "print(monthly_aggregates_ic.first().bandNames().getInfo())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_jaU7NuW3vm"
      },
      "source": [
        "# Export piece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hAGjY1tYW423"
      },
      "outputs": [],
      "source": [
        "def zonal_stats(ic, fc, params=None):\n",
        "    _params = {\n",
        "        'reducer': ee.Reducer.mean(),  # Change this as needed (e.g., sum, median)\n",
        "        'scale': 1000,  # change to 9km?\n",
        "        'crs': None,\n",
        "        'bands': None,\n",
        "        'bandsRename': None,\n",
        "        'imgProps': None,\n",
        "        'imgPropsRename': None,\n",
        "        'datetimeName': 'datetime',\n",
        "        'datetimeFormat': 'YYYY-MM-dd HH:mm:ss'\n",
        "    }\n",
        "    if params:\n",
        "        for param in params:\n",
        "            _params[param] = params[param] or _params[param]\n",
        "\n",
        "    img_rep = ic.first()\n",
        "    non_system_img_props = ee.Feature(None).copyProperties(img_rep).propertyNames()\n",
        "    if not _params['bands']:\n",
        "        _params['bands'] = img_rep.bandNames()\n",
        "    if not _params['bandsRename']:\n",
        "        _params['bandsRename'] = _params['bands']\n",
        "    if not _params['imgProps']:\n",
        "        _params['imgProps'] = non_system_img_props\n",
        "    if not _params['imgPropsRename']:\n",
        "        _params['imgPropsRename'] = _params['imgProps']\n",
        "\n",
        "    def map_function(img):\n",
        "        img = ee.Image(img.select(_params['bands'], _params['bandsRename']))\n",
        "        img = img.set(_params['datetimeName'], img.date().format(_params['datetimeFormat']))\n",
        "        img = img.set('timestamp', img.get('system:time_start'))\n",
        "        props_from = ee.List(_params['imgProps']).cat(ee.List([_params['datetimeName'], 'timestamp']))\n",
        "        props_to = ee.List(_params['imgPropsRename']).cat(ee.List([_params['datetimeName'], 'timestamp']))\n",
        "        img_props = img.toDictionary(props_from).rename(props_from, props_to)\n",
        "        fc_sub = fc.filterBounds(img.geometry())\n",
        "        return img.reduceRegions(\n",
        "            collection=fc_sub,\n",
        "            reducer=_params['reducer'],\n",
        "            scale=_params['scale'],\n",
        "            crs=_params['crs']\n",
        "        ).map(lambda f: f.set(img_props))\n",
        "\n",
        "    results = ic.map(map_function).flatten()\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aU7UWQ9sZQeI"
      },
      "outputs": [],
      "source": [
        "def export_era5_data_by_year(years, base_temps, feature_collection, export_folder):\n",
        "    # Create a list of (year, month) tuples\n",
        "    monthly_dates = [(year, month) for year in years for month in range(1, 13)]  # List of (year, month)\n",
        "\n",
        "    monthly_aggregates_ic = generate_monthly_aggregates(monthly_dates, base_temps)\n",
        "\n",
        "    # Apply zonal statistics to the monthly weather aggregates (image collection)\n",
        "    params = {'reducer': ee.Reducer.mean(), 'scale': 1000} # change to 9km?\n",
        "    ptsERA5monthly = zonal_stats(monthly_aggregates_ic, feature_collection, params)\n",
        "\n",
        "    # Define the export parameters\n",
        "    export_description = f\"monthly_aggregates_export_degree_days_{years[0]}-{years[-1]}\"\n",
        "    export_params = {\n",
        "        'collection': ptsERA5monthly,\n",
        "        'description': export_description,\n",
        "        'folder': export_folder,\n",
        "        'fileFormat': 'CSV'\n",
        "        }\n",
        "\n",
        "    # Start the export task\n",
        "    task = ee.batch.Export.table.toDrive(**export_params)\n",
        "    task.start()\n",
        "    print(f\"Exporting data: {export_description} to Google Drive in folder {export_folder}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HhVnGUyaVe08"
      },
      "outputs": [],
      "source": [
        "base_temps = list(range(-20, 36))\n",
        "export_folder = \"export_era5_monthly_20250428\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R446wKc0qJ-X",
        "outputId": "621c9567-0017-4e40-aa85-c9cc30d6acfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing years: [1995, 1996, 1997]\n",
            "Exporting data: monthly_aggregates_export_degree_days_1995-1997 to Google Drive in folder export_era5_monthly_20250428\n",
            "Processing years: [1998, 1999, 2000]\n",
            "Exporting data: monthly_aggregates_export_degree_days_1998-2000 to Google Drive in folder export_era5_monthly_20250428\n",
            "Processing years: [2001, 2002, 2003]\n",
            "Exporting data: monthly_aggregates_export_degree_days_2001-2003 to Google Drive in folder export_era5_monthly_20250428\n",
            "Processing years: [2004]\n",
            "Exporting data: monthly_aggregates_export_degree_days_2004-2004 to Google Drive in folder export_era5_monthly_20250428\n"
          ]
        }
      ],
      "source": [
        "start_year = 1995\n",
        "end_year = 2005\n",
        "chunk_size = 3 \n",
        "\n",
        "for year in range(start_year, end_year, chunk_size):\n",
        "  years = list(range(year, min(year + chunk_size, end_year)))\n",
        "  print(f\"Processing years: {years}\")\n",
        "  export_era5_data_by_year(years, base_temps, coordinates, export_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "noji_iPCpeOa",
        "outputId": "8925bd6d-fc5b-471e-d3eb-939ef53a234e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2001, 2002, 2003]\n",
            "Exporting data: monthly_aggregates_export_degree_days_2001-2003 to Google Drive in folder export_era5_monthly_20250428\n"
          ]
        }
      ],
      "source": [
        "years = list(range(2001, 2004)) # list(range(2022,2024))  # Ideal list of chunks: (1950, 1975), (1975, 2000), (2000, 2024)\n",
        "print(years)\n",
        "export_era5_data_by_year(years, base_temps, coordinates, export_folder)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1yiZc_V8Xt5C",
        "V_PAX6BSoOBG"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "itrdb-gee",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
